{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d sartazansari/e-commerce-sales-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzipping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"e-commerce-sales-dataset.zip\", \"r\") as file:\n",
    "    file.extractall(\"Raw Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"D:\\\\Projects\\\\Python\\\\ecom-data-clean\"\n",
    "raw_dir = os.path.join(project_dir, \"Raw Dataset\")\n",
    "cleaned_dir = os.path.join(project_dir, \"Clean Dataset\")\n",
    "data_folders = [\"Expense\", \"Inventory\", \"Pricing\", \"Sales\", \"Warehouse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting files in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_folders(folders):\n",
    "    \n",
    "    folder_files = {}\n",
    "    \n",
    "    for i, folder in enumerate(folders):\n",
    "        folder = os.path.join(raw_dir, folder)\n",
    "        \n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            files_arr = []\n",
    "            \n",
    "            for file in files:\n",
    "                files_arr.append(os.path.join(root, file))\n",
    "                \n",
    "            folder_files[data_folders[i]] = files_arr\n",
    "    return folder_files\n",
    "                \n",
    "\n",
    "data_files = get_data_from_folders(data_folders)\n",
    "\n",
    "pprint.pprint(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(files):\n",
    "    for key, value in files.items():\n",
    "        print(f\"{key}\\n\")\n",
    "        for item in value:\n",
    "            df = pd.read_csv(item, low_memory=False)\n",
    "            display(df.info())\n",
    "            display(df.head(5))\n",
    "            display(df.tail(5))\n",
    "            display(df.sample(5))\n",
    "            \n",
    "read_data(data_files)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_warehouse(df):\n",
    "    df = df.drop(columns=[\"index\"])\n",
    "    df = df.drop(columns=df.columns[2])\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.drop([0])\n",
    "    nan_index = df.iloc[:, 1].isna().idxmax()\n",
    "    df = df.iloc[:nan_index-1]\n",
    "    df.iloc[:, 1] = df.iloc[:, 1].str.replace(\"â‚¹\", \"\")\n",
    "    df.iloc[:, 1] = df.iloc[:, 1].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def clean_sales(df):\n",
    "    col = df.columns[df.columns.str.contains(\"Unnamed\")]\n",
    "    df = df.drop(columns=[\"index\", *col])\n",
    "    col = df.columns[df.columns.str.contains(\"Date\")]\n",
    "    df[col] = df[col].apply(pd.to_datetime, format=\"%m-%d-%y\", errors=\"coerce\")\n",
    "    col = df.columns[df.columns.str.contains(\"Qty\")]\n",
    "    df[col] = df[col].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def clean_sales_international(df):\n",
    "    df = df.drop(columns=[\"index\"])\n",
    "    header = [\"CUSTOMER\", \"DATE\", \"Months\", \"Style\", \"SKU\", \"PCS\", \"RATE\", \"GROSS AMT\", \"Stock\"]\n",
    "    temp_list = []\n",
    "    start = 0\n",
    "    row_with_header = True\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i].dropna().tolist()\n",
    "        if row and set(row).issubset(set(header)):\n",
    "            if np.array_equal(np.sort(header), np.sort(row)):\n",
    "                start = i+1\n",
    "                row_with_header = True\n",
    "                continue\n",
    "            elif row_with_header:\n",
    "                    temp_df = df[start : i]\n",
    "                    temp_df.columns = header\n",
    "                    row_with_header = False\n",
    "        elif i == len(df)-1:\n",
    "            temp_df = df[start:]\n",
    "            temp_df.columns = header\n",
    "            temp_list.append(temp_df)\n",
    "    df = pd.concat(temp_list)\n",
    "    col = df.columns[df.columns.str.contains(\"Date\")]\n",
    "    df[col] = df[col].apply(pd.to_datetime, format=\"%m-%d-%y\", errors=\"coerce\")\n",
    "    col = df.columns[df.columns.str.contains(\"Months\")]\n",
    "    df[col] = df[col].apply(pd.to_datetime, format=\"%b-%y\", errors=\"coerce\")\n",
    "    col = df.columns[df.columns.str.contains(\"|\".join([\"PCS\", \"RATE\", \"GROSS AMT\"]))]\n",
    "    df[col] = df[col].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def clean_pricing(df):\n",
    "    df = df.drop(columns=\"index\")\n",
    "    col = df.columns[df.columns.str.contains(\"|\".join([\"MRP\", \"TP\", \"Weight\"]))]\n",
    "    df[col] = df[col].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df[col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "def clean_inventory(df):\n",
    "    df = df.drop(columns=\"index\")\n",
    "    col = df.columns[df.columns.str.contains(\"Stock\")]\n",
    "    df[col] = df[col].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def clean_expense(df):\n",
    "    df = df.drop(columns=\"index\")\n",
    "    df = df.drop(columns=df.columns[0:1])\n",
    "    col = df.columns[1]\n",
    "    df[col] = df[col].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.dropna(subset=df.columns[1])\n",
    "    df.rename(columns=lambda col: \"Expense\" if \"Expance\" in col else col, inplace=True)\n",
    "    df.rename(columns=lambda col: \"Amount\" if \"Unnamed\" in col else col, inplace=True)\n",
    "    return df\n",
    "\n",
    "def clean_data(files):\n",
    "    for key, value in files.items():\n",
    "        print(key)\n",
    "        for item in value:\n",
    "            df = pd.read_csv(item, header=0, low_memory=False)\n",
    "            df = df.dropna(how=\"all\")\n",
    "            df = df.drop_duplicates()\n",
    "            match key:\n",
    "                case \"Expense\":\n",
    "                    df = clean_expense(df)\n",
    "                case \"Inventory\":\n",
    "                    df = clean_inventory(df)\n",
    "                case \"Pricing\":\n",
    "                    df = clean_pricing(df)\n",
    "                case \"Sales\":\n",
    "                    if \"International\" in item:\n",
    "                        df = clean_sales_international(df)\n",
    "                    else:\n",
    "                        df = clean_sales(df)\n",
    "                case \"Warehouse\":\n",
    "                    df = clean_warehouse(df)\n",
    "            filename = \"Cleaned_\" + os.path.basename(item)\n",
    "            directory = os.path.join(cleaned_dir, key)\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            df.to_csv(os.path.join(directory, filename), index=False)\n",
    "            display(df) \n",
    "            \n",
    "\n",
    "clean_data(data_files)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
